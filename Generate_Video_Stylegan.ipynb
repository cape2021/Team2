{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generate Video Stylegan.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXcg+dpWd1Ha8QnMqVaj/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cape2021/Team2/blob/main/Generate_Video_Stylegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI3noOj0JS77"
      },
      "source": [
        "# **Requirements and Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Hdx9DCJVRt"
      },
      "source": [
        "#Use of Tensor flow 1.X is recomended for the current notebook\r\n",
        "%tensorflow_version 1.x #If you are using Google Colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmViT9rhJV2m"
      },
      "source": [
        "%pip install Google-Colab-Transfer #If you are Using Google Colab "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6fhAn8pJjNU"
      },
      "source": [
        "**Mount Google Drive** \r\n",
        "\r\n",
        "In case you are using google cloud to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2xgfuYWJcWN"
      },
      "source": [
        "import colab_transfer\n",
        "\n",
        "gd = colab_transfer.get_path_to_home_of_google_drive()\n",
        "lm = colab_transfer.get_path_to_home_of_local_machine()\n",
        "\n",
        "colab_transfer.mount_google_drive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmzu3IjqJ_iO"
      },
      "source": [
        "**Clone Stylegan2-ada  Repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp9-Hte0Jk_D"
      },
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada.git\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfMgaFk2YcnQ"
      },
      "source": [
        "**Generate Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLUBc_YXSZp6"
      },
      "source": [
        "# reference: https://arxiv.org/pdf/2009.05673.pdf\n",
        "\n",
        "import sys\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sys.path.insert(0, \"/content/stylegan2-ada\")\n",
        "\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "\n",
        "def seed2vec(Gs, seed):\n",
        "  rnd = np.random.RandomState(seed)\n",
        "  return rnd.randn(1, *Gs.input_shape[1:])\n",
        "\n",
        "def init_random_state(Gs, seed):\n",
        "  rnd = np.random.RandomState(seed) \n",
        "  noise_vars = [var for name, var in Gs.components.synthesis.vars.items() if name.startswith('noise')]\n",
        "  tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "\n",
        "def display_image(image):\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "def generate_image(Gs, z, truncation_psi):\n",
        "    # Render images for dlatents initialized from random seeds.\n",
        "    Gs_kwargs = {\n",
        "        'output_transform': dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True),\n",
        "        'randomize_noise': False\n",
        "    }\n",
        "    if truncation_psi is not None:\n",
        "        Gs_kwargs['truncation_psi'] = truncation_psi\n",
        "\n",
        "    label = np.zeros([1] + Gs.input_shapes[1][1:])\n",
        "    images = Gs.run(z, label, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "    return images[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qet8UNHOWJ5"
      },
      "source": [
        "import IPython.display\r\n",
        "\r\n",
        "tflib.init_tf()\r\n",
        "\r\n",
        "#add your pickle\r\n",
        "with open(\"/content/drive/MyDrive/PEIDATASET/peidata5OUT/00067-peidata5-auto_no_ramp1-kimg30000-p0.713-resumecustom-freezed10/network-snapshot-029567.pkl\", \"rb\") as fp:\r\n",
        "  _G, _D, Gs = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEX5p6fvOepu"
      },
      "source": [
        "# Choose your own starting and ending seed.\r\n",
        "SEED_FROM = 2000\r\n",
        "SEED_TO = 2200\r\n",
        "\r\n",
        "# Generate the images for the seeds.\r\n",
        "for i in range(SEED_FROM, SEED_TO):\r\n",
        "  print(f\"Seed {i}\")\r\n",
        "  init_random_state(Gs, 10)\r\n",
        "  z = seed2vec(Gs, i)\r\n",
        "  img = generate_image(Gs, z, 1.0)\r\n",
        "  display_image(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd63OB7mOj6B"
      },
      "source": [
        "# Choose your seeds to morph through and the number of steps to take to get to each.\r\n",
        "SEEDS = [2182,2180]\r\n",
        "import random\r\n",
        "random.shuffle(SEEDS)\r\n",
        "SEEDS.append(SEEDS[0])\r\n",
        "STEPS = 50\r\n",
        "\r\n",
        "# Remove any prior results\r\n",
        "!rm /content/results/* \r\n",
        "\r\n",
        "from tqdm.notebook import tqdm\r\n",
        "\r\n",
        "os.makedirs(\"./results/\", exist_ok=True)\r\n",
        "\r\n",
        "# Generate the images for the video.\r\n",
        "idx = 0\r\n",
        "for i in range(len(SEEDS)-1):\r\n",
        "  v1 = seed2vec(Gs, SEEDS[i])\r\n",
        "  v2 = seed2vec(Gs, SEEDS[i+1])\r\n",
        "\r\n",
        "  diff = v2 - v1\r\n",
        "  step = diff / STEPS\r\n",
        "  current = v1.copy()\r\n",
        "\r\n",
        "  for j in tqdm(range(STEPS), desc=f\"Seed {SEEDS[i]}\"):\r\n",
        "    current = current + step\r\n",
        "    init_random_state(Gs, 10)\r\n",
        "    img = generate_image(Gs, current, 1.0)\r\n",
        "    PIL.Image.fromarray(img, 'RGB').save(f'./results/frame-{idx}.png')\r\n",
        "    idx+=1\r\n",
        " \r\n",
        "# Link the images into a video.\r\n",
        "!ffmpeg -r 30 -i /content/results/frame-%d.png -vcodec mpeg4 -y movie.mp4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}